{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will allow the notebook to run faster\n",
    "from pathlib import Path\n",
    "use_cache = True\n",
    "OUTPUT_PATH = Path('/ds/hamel/code_search_data/outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Requisite: Make Sure you have the right files prepared from Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have a directory with these files:\n",
    "\n",
    "1. `{train/valid/test.function}` - these are python function definitions tokenized (by space), 1 line per function.\n",
    "2. `{train/valid/test.docstring}` - these are docstrings that correspond to each of the python function definitions, and have a 1:1 correspondence with the lines in *.function files.\n",
    "3. `{train/valid/test.lineage}` - every line in this file contains a link back to the original location (github repo link) where the code was retrieved.  There is a 1:1 correspondence with the lines in this file and the other two files. This is useful for debugging.\n",
    "\n",
    "Note: I have an `outputs` sub-folder where I dump intermediate and final outputs.  This is optional for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.3G\r\n",
      "drwxr-xr-x  3 1001 1001 6.0K May 15 02:38 .\r\n",
      "drwxrwxrwx 27 root root 6.0K May 15 01:08 ..\r\n",
      "drwxr-xr-x  3 root root 6.0K May 15 03:18 outputs\r\n",
      "-rw-r--r--  1 root root 3.5M May 15 02:36 test.docstring\r\n",
      "-rw-r--r--  1 root root  16M May 15 02:37 test.function\r\n",
      "-rw-r--r--  1 root root 4.4M May 15 02:38 test.lineage\r\n",
      "-rw-r--r--  1 root root 325M May 15 02:37 train.docstring\r\n",
      "-rw-r--r--  1 root root 1.4G May 15 02:37 train.function\r\n",
      "-rw-r--r--  1 root root 413M May 15 02:38 train.lineage\r\n",
      "-rw-r--r--  1 root root  14M May 15 02:37 valid.docstring\r\n",
      "-rw-r--r--  1 root root  60M May 15 02:37 valid.function\r\n",
      "-rw-r--r--  1 root root  18M May 15 02:38 valid.lineage\r\n"
     ]
    }
   ],
   "source": [
    "! ls /ds/hamel/code_search_data -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Text In From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from general_utils import read_training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Num rows for encoder training + validation input: 4,978,625\n",
      "WARNING:root:Num rows for encoder holdout input: 50,290\n",
      "WARNING:root:Num rows for decoder training + validation input: 4,978,625\n",
      "WARNING:root:Num rows for decoder holdout input: 50,290\n"
     ]
    }
   ],
   "source": [
    "train_code, holdout_code, train_comment, holdout_comment = read_training_files('/ds/hamel/code_search_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_code) == len(train_comment)\n",
    "assert len(holdout_code) == len(holdout_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Not fitting transform function because use_cache=True\n"
     ]
    }
   ],
   "source": [
    "from ktext.preprocess import processor\n",
    "\n",
    "if not use_cache:    \n",
    "    code_proc = processor(hueristic_pct_padding=.7, keep_n=20000)\n",
    "    t_code = code_proc.fit_transform(train_code)\n",
    "\n",
    "    comment_proc = processor(append_indicators=True, hueristic_pct_padding=.7, keep_n=14000, padding ='post')\n",
    "    t_comment = comment_proc.fit_transform(train_comment)\n",
    "\n",
    "elif use_cache:\n",
    "    logging.warning('Not fitting transform function because use_cache=True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as dpickle\n",
    "import numpy as np\n",
    "\n",
    "if not use_cache:\n",
    "    # Save the preprocessor\n",
    "    with open(OUTPUT_PATH/'py_code_proc.dpkl', 'wb') as f:\n",
    "        dpickle.dump(code_proc, f)\n",
    "\n",
    "    with open(OUTPUT_PATH/'py_comment_proc.dpkl', 'wb') as f:\n",
    "        dpickle.dump(comment_proc, f)\n",
    "\n",
    "    # Save the processed data\n",
    "    np.save(OUTPUT_PATH/'py_t_code_vecs.npy', t_code)\n",
    "    np.save(OUTPUT_PATH/'py_t_comment_vecs.npy', t_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrange data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder input: (4978625, 55)\n",
      "Shape of decoder input: (4978625, 14)\n",
      "Shape of decoder target: (4978625, 14)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from seq2seq_utils import load_decoder_inputs, load_encoder_inputs, load_text_processor\n",
    "\n",
    "\n",
    "encoder_input_data, encoder_seq_len = load_encoder_inputs(OUTPUT_PATH/'py_t_code_vecs.npy')\n",
    "decoder_input_data, decoder_target_data = load_decoder_inputs(OUTPUT_PATH/'py_t_comment_vecs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary for /ds/hamel/code_search_data/outputs/py_code_proc.dpkl: 20,002\n",
      "Size of vocabulary for /ds/hamel/code_search_data/outputs/py_comment_proc.dpkl: 15,002\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens, enc_pp = load_text_processor(OUTPUT_PATH/'py_code_proc.dpkl')\n",
    "num_decoder_tokens, dec_pp = load_text_processor(OUTPUT_PATH/'py_comment_proc.dpkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Seq2Seq Model For Summarizing Code - (This Is Only For Transfer Learning)\n",
    "\n",
    "Will reuse this for the code search task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_utils import build_seq2seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_Model = build_seq2seq_model(word_emb_dim=800,\n",
    "                                    hidden_state_dim=1200,\n",
    "                                    encoder_seq_len=encoder_seq_len,\n",
    "                                    num_encoder_tokens=num_encoder_tokens,\n",
    "                                    num_decoder_tokens=num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder-Input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Word-Embedding (Embeddi (None, None, 800)    12001600    Decoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Input (InputLayer)      (None, 55)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-1 (BatchNorma (None, None, 800)    3200        Decoder-Word-Embedding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Model (Model)           (None, 1200)         23208400    Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-GRU (GRU)               [(None, None, 1200), 7203600     Decoder-Batchnorm-1[0][0]        \n",
      "                                                                 Encoder-Model[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder-Batchnorm-2 (BatchNorma (None, None, 1200)   4800        Decoder-GRU[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Final-Output-Dense (Dense)      (None, None, 15002)  18017402    Decoder-Batchnorm-2[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 60,439,002\n",
      "Trainable params: 60,433,402\n",
      "Non-trainable params: 5,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning:\n",
    "\n",
    "if Setting `use_cache = False` this next part takes 4 days to train on AWS on a `p3.2xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Not re-training function summarizer seq2seq model because use_cache=True\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "if not use_cache:\n",
    "\n",
    "    from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "    import numpy as np\n",
    "    from keras import optimizers\n",
    "\n",
    "    seq2seq_Model.compile(optimizer=optimizers.Nadam(lr=0.00005), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    script_name_base = 'py_func_sum_v6_'\n",
    "    csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                       save_best_only=True)\n",
    "\n",
    "    batch_size = 900\n",
    "    epochs = 500\n",
    "    history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.12, callbacks=[csv_logger, model_checkpoint])\n",
    "\n",
    "elif use_cache:\n",
    "    logging.warning('Not re-training function summarizer seq2seq model because use_cache=True')\n",
    "    seq2seq_Model = load_model(OUTPUT_PATH/'py_func_sum_v5_.epoch50-val1.68161.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 44465 =================\n",
      "\n",
      "Original Input:\n",
      " def purge_samples self raise NotImplementedError Not supported\n",
      " \n",
      "\n",
      "Original Output:\n",
      " removes all decision samples\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " purge samples from the database\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 2179 =================\n",
      "\n",
      "Original Input:\n",
      " app teardown_appcontext def close_db_connection exception top _app_ctx_stack top if hasattr top sqlite_db top sqlite_db close\n",
      " \n",
      "\n",
      "Original Output:\n",
      " closes the database again at the end of the request .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " closes the database again at the end of the request\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 39100 =================\n",
      "\n",
      "Original Input:\n",
      " def make_dummy_protein_sequence n_supporting_variant_reads n_supporting_variant_sequences n_supporting_reference_transcripts n_total_variant_sequences None n_total_variant_reads None n_total_reference_transcripts None gene TP53 amino_acids MKHW cdna_sequence CCCATGAAACACTGGTAG variant_cdna_interval_start 8 variant_cdna_interval_end 9 variant_aa_interval_start 1 variant_aa_interval_end 2 number_mismatches 1 if n_total_variant_reads is None n_total_variant_reads n_supporting_variant_reads if n_total_variant_sequences is None n_total_variant_sequences n_supporting_variant_sequences if n_total_reference_transcripts is None n_total_reference_transcripts n_total_reference_transcripts assert n_supporting_variant_sequences n_supporting_variant_reads assert n_supporting_variant_sequences n_total_variant_sequences assert n_supporting_reference_transcripts n_total_reference_transcripts n_translations n_total_reference_transcripts n_total_variant_sequences translation make_dummy_translation return ProteinSequence translations translation n_translations overlapping_reads None n_total_variant_reads ref_reads alt_reads None n_total_variant_reads alt_reads_supporting_protein_sequence None n_supporting_variant_reads transcripts_supporting_protein_sequence None n_supporting_reference_transcripts transcripts_overlapping_variant None n_supporting_reference_transcripts gene gene amino_acids amino_acids variant_aa_interval_start variant_aa_interval_start variant_aa_interval_end variant_aa_interval_end ends_with_stop_codon translation ends_with_stop_codon frameshift translation frameshift\n",
      " \n",
      "\n",
      "Original Output:\n",
      " creates proteinsequence object with none filled in for most fields\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " create a dummy vcf file supporting design and variants\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 5333 =================\n",
      "\n",
      "Original Input:\n",
      " def __init__ self data volatile False self data data self rank 0 self volatile volatile self splitter weakref ref lambda 0 self grad None self creator None\n",
      " \n",
      "\n",
      "Original Output:\n",
      " initializes a variable .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " initializes the data object\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 40652 =================\n",
      "\n",
      "Original Input:\n",
      " def add self filename try self _recentFiles remove filename except pass self _recentFiles insert 0 filename self save self _createMenu\n",
      " \n",
      "\n",
      "Original Output:\n",
      " add a filename to the recent file list ( automatically save and add to menu )\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " add a file to the list of recent files\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 25681 =================\n",
      "\n",
      "Original Input:\n",
      " def java_executable java_home getenv JAVA_HOME java_bin os path join bin java if java_home and access os path join java_home java_bin X_OK return os path join java_home java_bin else return java\n",
      " \n",
      "\n",
      "Original Output:\n",
      " return the executable name of the java interpreter .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " return the executable name of the java interpreter\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 21930 =================\n",
      "\n",
      "Original Input:\n",
      " def traits return __TRAITS\n",
      " \n",
      "\n",
      "Original Output:\n",
      " return all traits\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " return a traits object representing the current configuration\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 17235 =================\n",
      "\n",
      "Original Input:\n",
      " def __init__ self heading 0 roll 0 pitch 0 self data heading roll pitch self heading heading self roll roll self pitch pitch\n",
      " \n",
      "\n",
      "Original Output:\n",
      " initializes the eulerangles object .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " initialize a heading\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 1350 =================\n",
      "\n",
      "Original Input:\n",
      " def _get_next request next request POST get next request GET get next request META get HTTP_REFERER None if not next next request path return next\n",
      " \n",
      "\n",
      "Original Output:\n",
      " the part that 's the least straightforward about views in this module is how they determine their redirects after they have finished computation .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " the part that s the least straightforward about views in this module is how how\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 26671 =================\n",
      "\n",
      "Original Input:\n",
      " def queueMerge l if len l 0 return l q Queue for x in l q enqueue x while len q 1 a q dequeue b q dequeue i j 0 0 c while i len a and j len b if a i b j c append a i i 1 else c append b j j 1 c a i b j q enqueue c return q dequeue\n",
      " \n",
      "\n",
      "Original Output:\n",
      " iterativna razliƒçica mergesort - a .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " type l list int rtype list list int\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 32942 =================\n",
      "\n",
      "Original Input:\n",
      " def safe_unicode str return str encode ascii replace decode utf 8\n",
      " \n",
      "\n",
      "Original Output:\n",
      " strip non - ascii characters out of a unicode string .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " convert a string to ascii\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 17586 =================\n",
      "\n",
      "Original Input:\n",
      " property def detail_state self if self coffeemaker_mode is not None return self wemo mode_string if self insight_params standby_state int self insight_params state if standby_state WEMO_ON return STATE_ON elif standby_state WEMO_OFF return STATE_OFF elif standby_state WEMO_STANDBY return STATE_STANDBY else return STATE_UNKNOWN\n",
      " \n",
      "\n",
      "Original Output:\n",
      " return the state of the device .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " return the state of the device\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 11002 =================\n",
      "\n",
      "Original Input:\n",
      " def register import sys _monkey_patch_requests if s blender __name__ in sys modules import importlib def reload_mod name modname s s __name__ name module importlib reload sys modules modname sys modules modname module return module reload_mod blendfile reload_mod home_project reload_mod utils blender reload_mod blender async_loop reload_mod async_loop texture_browser reload_mod texture_browser settings_sync reload_mod settings_sync image_sharing reload_mod image_sharing else from import blender texture_browser async_loop settings_sync blendfile home_project image_sharing async_loop setup_asyncio_executor async_loop register texture_browser register blender register settings_sync register image_sharing register\n",
      " \n",
      "\n",
      "Original Output:\n",
      " late - loads and registers the blender - dependent submodules .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " register the module and its dependencies\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 35126 =================\n",
      "\n",
      "Original Input:\n",
      " def test_address_header_decoding self mailsploit_sample utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y utf 8 Q 00 utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y mailsploit com expected_result utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y utf 8 Q utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y mailsploit com self assertEqual u2u_decode decode_address mailsploit_sample expected_result mailsploit_sample utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y utf 8 Q 0A 00 utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y utf 8 Q 0A 00 mailsploit com expected_result potus whitehouse gov utf 8 b cG90dXNAd2hpdGVob3VzZS5nb3Y utf 8 Q mailsploit com self assertEqual u2u_decode decode_address mailsploit_sample expected_result\n",
      " \n",
      "\n",
      "Original Output:\n",
      " check address decoding .\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " test decoding of header with unicode encoding\n",
      "\n",
      "\n",
      "==============================================\n",
      "============== Example # 50120 =================\n",
      "\n",
      "Original Input:\n",
      " def test_ko_1 jsv jsonvalidate Validate with pytest raises ValidationError as excinfo jsv validate_file os path join curpath json_ko_1 js excinfo match 24 is greater\n",
      " \n",
      "\n",
      "Original Output:\n",
      " test a malformed json file\n",
      "\n",
      "\n",
      "****** Predicted Output ******:\n",
      " expect to fail when the ko file is not in the list\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_utils import Seq2Seq_Inference\n",
    "import pandas as pd\n",
    "\n",
    "seq2seq_inf = Seq2Seq_Inference(encoder_preprocessor=enc_pp,\n",
    "                                 decoder_preprocessor=dec_pp,\n",
    "                                 seq2seq_model=seq2seq_Model)\n",
    "\n",
    "demo_testdf = pd.DataFrame({'code':holdout_code, 'comment':holdout_comment, 'ref':''})\n",
    "seq2seq_inf.demo_model_predictions(n=15, df=demo_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Generating predictions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01938e512351401da2d5c363fbb559fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50290), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq2seq_inf.evaluate_model(input_strings=holdout_code, \n",
    "                           output_strings=holdout_comment, \n",
    "                           max_len=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
